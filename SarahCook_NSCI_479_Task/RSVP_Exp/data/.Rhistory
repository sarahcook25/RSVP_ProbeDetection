# Discard connection
rm(con)
library(dplyr)
library(purrr)
library(jsonlite)
d.meta <- map_dfr(d$metadata, ~ {
meta_row <- fromJSON(.x)
meta_row <- as_tibble(meta_row)
meta_row$observation <- meta_row$id     # observation from metadata id
meta_row
})
d <- d %>%
bind_cols(d.meta) %>%
select(
-metadata # Remove metadata column
)
# Remove temporary data frame
#rm(d.meta)
library(dplyr)
filtered_df <- d %>%
# Keep rows where timestamp starts with '2025'
filter(startsWith(timestamp, "2025")) %>%
# Count how many times each observation appears
add_count(observation) %>%
# Keep only rows where observation appears more than once
filter(n > 10) %>%
select(-n)  # Remove the count column if not needed
# View result
print(filtered_df)
count_unique <- function(x) {
return(length(unique(x)))
}
information_preserved <- function(x, length) {
return(
count_unique(str_sub(x, end=i)) ==
count_unique(x)
)
}
# Figure out the length of the random ids needed
# to preserve the information therein. (five characters
# should usually be enougth, but better safe)
for (i in 5:36) {
if (
information_preserved(d$session, i) &&
information_preserved(d$observation, i)
) {
break()
}
}
d <- d %>%
dplyr::mutate(
session=str_sub(session, end=i),
observation=str_sub(observation, end=20) #change this to 20
)
rm(i, count_unique, information_preserved)
count_unique <- function(x) {
return(length(unique(x)))
}
information_preserved <- function(x, length) {
return(
count_unique(str_sub(x, end=i)) ==
count_unique(x)
)
}
# Figure out the length of the random ids needed
# to preserve the information therein. (five characters
# should usually be enougth, but better safe)
for (i in 5:36) {
if (
information_preserved(d$session, i) &&
information_preserved(d$observation, i)
) {
break()
}
}
d <- d %>%
dplyr::mutate(
session=str_sub(session, end=i),
observation=str_sub(observation, end=20) #change this to 20
)
rm(i, count_unique, information_preserved)
parseJSON <- function(input) {
return(input %>%
fromJSON(flatten=T) %>% {
# Coerce lists
if (class(.) == 'list') {
discard(., is.null) %>%
as_tibble()
} else {
.
} } %>%
# Sanitize names
janitor::clean_names() %>%
# Use only strings for now, and re-encode types later
mutate_all(as.character)
)
}
d.full <- d %>%
dplyr::filter(payload == 'full')
if (nrow(d.full) > 0) {
d.full %>%
group_by(observation, id) %>%
do(
{ map_dfr(.$data, parseJSON) } %>%
bind_rows()
) %>%
ungroup() %>%
select(-id) -> d.full
} else {
# If there are no full datasets, start from an entirely empty df
# in order to avoid introducing unwanted columns into the following
# merge steps.
d.full <- tibble()
d.full$observation <- c()
}
# 'Connect' to database
con <- dbConnect(
drv=RSQLite::SQLite(),
dbname='data.sqlite'
)
# Load packages
install.packages("pacman")
require('pacman')
p_load('RSQLite', 'jsonlite', 'tidyverse', 'janitor')
library(magrittr)
# 'Connect' to database
con <- dbConnect(
drv=RSQLite::SQLite(),
dbname='data.sqlite'
)
# Extract main table
d <- dbGetQuery(
conn=con,
statement='SELECT * FROM labjs'
)
# Close connection
dbDisconnect(
conn=con
)
# Discard connection
rm(con)
library(dplyr)
library(purrr)
library(jsonlite)
d.meta <- map_dfr(d$metadata, ~ {
meta_row <- fromJSON(.x)
meta_row <- as_tibble(meta_row)
meta_row$observation <- meta_row$id     # observation from metadata id
meta_row
})
d <- d %>%
bind_cols(d.meta) %>%
select(
-metadata # Remove metadata column
)
# Remove temporary data frame
#rm(d.meta)
library(dplyr)
filtered_df <- d %>%
# Keep rows where timestamp starts with '2025'
filter(startsWith(timestamp, "2025")) %>%
# Count how many times each observation appears
add_count(observation) %>%
# Keep only rows where observation appears more than once
filter(n > 10) %>%
select(-n)  # Remove the count column if not needed
# View result
print(filtered_df)
count_unique <- function(x) {
return(length(unique(x)))
}
information_preserved <- function(x, length) {
return(
count_unique(str_sub(x, end=i)) ==
count_unique(x)
)
}
# Figure out the length of the random ids needed
# to preserve the information therein. (five characters
# should usually be enougth, but better safe)
for (i in 5:36) {
if (
information_preserved(d$session, i) &&
information_preserved(d$observation, i)
) {
break()
}
}
d <- d %>%
dplyr::mutate(
session=str_sub(session, end=i),
observation=str_sub(observation, end=20) #change this to 20
)
rm(i, count_unique, information_preserved)
parseJSON <- function(input) {
return(input %>%
fromJSON(flatten=T) %>% {
# Coerce lists
if (class(.) == 'list') {
discard(., is.null) %>%
as_tibble()
} else {
.
} } %>%
# Sanitize names
janitor::clean_names() %>%
# Use only strings for now, and re-encode types later
mutate_all(as.character)
)
}
filtered_df %>%
dplyr::filter(payload %in% c('incremental', 'latest')) %>%
group_by(observation) %>%
do(
{ map_dfr(.$data, parseJSON) } %>%
bind_rows()
) %>%
ungroup() -> d.incremental
d.output <- d.incremental %>%
bind_rows(
d.incremental %>% filter(!(observation %in% d.incremental$observation))
) %>%
type_convert()
View(d.output)
View(d.output)
View(d.output)
View(d.output)
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
write_csv(df_filtered, 'output_5_4')
View(df_filtered)
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
# Assume your dataframe is called df and the timestamp column is called 'timestamp'
df_filtered <- df_filtered %>%
mutate(timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S")) %>%
arrange(timestamp)
write_csv(df_filtered, 'output_5_4')
View(df_filtered)
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
# Assume your dataframe is called df and the timestamp column is called 'timestamp'
df_filtered <- df_filtered %>%
mutate(timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S")) %>%
arrange(timestamp)
write_csv(df_filtered, 'output_5_4_230')
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top", "condition")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
# Assume your dataframe is called df and the timestamp column is called 'timestamp'
df_filtered <- df_filtered %>%
mutate(timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S")) %>%
arrange(timestamp)
write_csv(df_filtered, 'output_5_4_230')
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top", "condition")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
# Assume your dataframe is called df and the timestamp column is called 'timestamp'
df_filtered <- df_filtered %>%
mutate(timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S")) %>%
arrange(timestamp)
write_csv(df_filtered, 'output_5_4_234')
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top", "condition", "sub_seq")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
# Assume your dataframe is called df and the timestamp column is called 'timestamp'
df_filtered <- df_filtered %>%
mutate(timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S")) %>%
arrange(timestamp)
write_csv(df_filtered, 'output_5_4_235')
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top", "condition", "sub_seq", "duration")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
# Assume your dataframe is called df and the timestamp column is called 'timestamp'
df_filtered <- df_filtered %>%
mutate(timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S")) %>%
arrange(timestamp)
write_csv(df_filtered, 'output_5_4_235')
# Apply mapping
d.output$duration <- sapply(d.output$duration, function(x) {
if (is.na(x)) {
return(NA)  # Keep NA as NA
} else if (x >= 32 & x <= 35) {
return(34)
} else if (x >= 82 & x <= 85) {
return(84)
} else if (x >= 165 & x <= 168) {
return(167)
} else {
return(x)
}
})
# Loop through the rows of the dataframe
for (i in 3:nrow(d.output)) {  # Start from row 3 to avoid index out of bounds
if (d.output$sender[i] == "Test_no_img") {
d.output$duration[i] <- d.output$duration[i - 3]
}
if (d.output$sender[i] == "Test_probe") {
d.output$duration[i] <- d.output$duration[i - 4]
}
}
library(dplyr)
# Given dataframe
df.output <- d.output
# List of columns to keep
cols_to_keep <- c("sender", "observation", "timestamp", "is_probe", "trial_type", "response", "response_action", "target_img_1", "target_img_2", "target_img_3", "target_img_4", "target_img_5", "target_img_6", "probesize0", "probesize1", "probesize2", "probesize3", "probesize4", "probesize5", "probe_left", "probe_top", "condition", "sub_seq", "duration")
# Keep only these columns
df_filtered <- df.output %>% select(all_of(cols_to_keep))
# Assume your dataframe is called df and the timestamp column is called 'timestamp'
df_filtered <- df_filtered %>%
mutate(timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S")) %>%
arrange(timestamp)
write_csv(df_filtered, 'output_5_4_244')
View(filtered_df)
View(df.output)
View(df_filtered)
View(df_filtered)
View(df_filtered)
# Load packages
install.packages("pacman")
